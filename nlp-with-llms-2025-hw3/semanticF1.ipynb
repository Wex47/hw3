{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d4fc3a",
   "metadata": {},
   "source": [
    "# Semantic F1 Evaluation Metric\n",
    "\n",
    "The DSPy SemanticF1 evaluation metric uses an LLM to compare a candidate textual answer to a gold answer.\n",
    "It computes a \"precision\", \"recall\" and \"F1\" measure of how well the candidate answer provides the information expected in the gold answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3946ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "lm = dspy.LM('xai/grok-3-mini', max_tokens=6000, temperature=0.1, top_p=0.9)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/static-retrieval-mrl-en-v1\", device=\"cpu\")\n",
    "embedder = dspy.Embedder(model.encode)\n",
    "\n",
    "# Traverse a directory and read html files - extract text from the html files\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "def read_html_files(dir_name, directory=\"../PragmatiCQA-sources\"):\n",
    "    texts = []\n",
    "    for filename in os.listdir(os.path.join(directory, dir_name)):\n",
    "        if filename.endswith(\".html\"):\n",
    "            with open(os.path.join(directory, dir_name, filename), 'r', encoding='utf-8') as file:\n",
    "                soup = BeautifulSoup(file, 'html.parser')\n",
    "                texts.append(soup.get_text())\n",
    "    return texts\n",
    "\n",
    "# Perform retrieval on a specific topic: read html files for the corresponding folder, index\n",
    "def make_search(topic):\n",
    "    corpus = read_html_files(topic)\n",
    "    max_characters = 10000 \n",
    "    topk_docs_to_retrieve = 5  # number of documents to retrieve per search query\n",
    "    return dspy.retrievers.Embeddings(embedder=embedder, corpus=corpus, k=topk_docs_to_retrieve, brute_force_threshold=max_characters)\n",
    "\n",
    "# Make a RAG module with a given retriever.\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, search):\n",
    "        self.search = search\n",
    "        self.respond = dspy.ChainOfThought('context, question -> response')\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.search(question).passages\n",
    "        return self.respond(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47bbaca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load jsonl from dataset directory\n",
    "import json\n",
    "import os  \n",
    "\n",
    "def read_data(filename, dataset_dir=\"../PragmatiCQA/data\"):\n",
    "    corpus = []\n",
    "    with open(os.path.join(dataset_dir, filename), 'r') as f:\n",
    "        for line in f:\n",
    "            corpus.append(json.loads(line))\n",
    "    return corpus\n",
    "\n",
    "pcqa_test = read_data(\"test.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5925098f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'community': 'The Legend of Zelda',\n",
      " 'genre': 'Games',\n",
      " 'qas': [{'a': 'The Legend of Zelda came out as early as 1986 for the Famicom '\n",
      "               'in Japan, and was later released in the western world, '\n",
      "               'including Europe and the US in 1987. Would you like to know '\n",
      "               'about the story?',\n",
      "          'a_meta': {'literal_obj': [{'endKey': '9cbccabd-66be-4a46-bd8b-f59a299c987d',\n",
      "                                      'startKey': '1f4f808a-8560-4894-b892-15fa3c33887a',\n",
      "                                      'text': 'FDS release February 21, '\n",
      "                                              '1986\\n'},\n",
      "                                     {'endKey': '738bff65-b4f9-4660-bd18-79722ed67a40',\n",
      "                                      'startKey': 'a0d9d5c5-18bb-4be4-825e-fca2900db18e',\n",
      "                                      'text': 'The Legend of Zelda is the '\n",
      "                                              'first installment of the Zelda '\n",
      "                                              'series. '},\n",
      "                                     {'endKey': '738bff65-b4f9-4660-bd18-79722ed67a40',\n",
      "                                      'startKey': '738bff65-b4f9-4660-bd18-79722ed67a40',\n",
      "                                      'text': ' It centers its plot around a '\n",
      "                                              'boy named Link , who becomes '\n",
      "                                              'the central protagonist '\n",
      "                                              'throughout the series. '}],\n",
      "                     'pragmatic_obj': [{'endKey': '738bff65-b4f9-4660-bd18-79722ed67a40',\n",
      "                                        'startKey': '738bff65-b4f9-4660-bd18-79722ed67a40',\n",
      "                                        'text': 'It came out as early as 1986 '\n",
      "                                                'for the Famicom in Japan, and '\n",
      "                                                'was later released in the '\n",
      "                                                'western world, including '\n",
      "                                                'Europe and the US in 1987.'}]},\n",
      "          'human_eval': ['2', '1', '1', '1', '2'],\n",
      "          'q': 'What year did the Legend of Zelda come out?'},\n",
      "         {'a': 'The series centers on Link, the playable character and '\n",
      "               'protagonist. Link is often given the task of rescuing Princess '\n",
      "               \"Zelda and the kingdom of Hyrule from Ganon, who is the series' \"\n",
      "               'principal antagonist; however, other settings and antagonists '\n",
      "               'have appeared in several games.',\n",
      "          'a_meta': {'literal_obj': [{'endKey': 'f4c7a28e-d931-4b5d-a4f1-230ceb5df906',\n",
      "                                      'startKey': 'f4c7a28e-d931-4b5d-a4f1-230ceb5df906',\n",
      "                                      'text': '\"In the midst of this chaos, in '\n",
      "                                              'a little kingdom in the land of '\n",
      "                                              'Hyrule, a legend was being '\n",
      "                                              'handed down from generation to '\n",
      "                                              'generation, the legend of the '\n",
      "                                              \"'Triforce'; golden triangles \"\n",
      "                                              'possessing mystical powers. '},\n",
      "                                     {'endKey': 'fff80c54-6c21-4366-9bb5-340d6ef885cd',\n",
      "                                      'startKey': 'fff80c54-6c21-4366-9bb5-340d6ef885cd',\n",
      "                                      'text': '\"A long, long time ago the '\n",
      "                                              'World was in an age of Chaos.'}],\n",
      "                     'pragmatic_obj': [{'endKey': '00c5493d-39bc-455c-8dad-d559664ca2bc',\n",
      "                                        'startKey': '7638180a-1da5-449e-895b-77b03f7502ae',\n",
      "                                        'text': 'Characters\\n'\n",
      "                                                'Bosses\\n'\n",
      "                                                'Enemies\\n'\n",
      "                                                'Dungeons\\n'\n",
      "                                                'Items\\n'\n",
      "                                                'Credits\\n'\n",
      "                                                'Glitches'}]},\n",
      "          'human_eval': ['2', '4', '5', '5', '3'],\n",
      "          'q': 'Yes who are the main characters in the story?'},\n",
      "         {'a': 'The first setting is the \"Dungeon Exploration\" barring Link '\n",
      "               \"'s progress are creatures he must battle to locate the \"\n",
      "               'entrances to nine underground Dungeons.  Each Dungeon is a '\n",
      "               'unique, maze-like collection of rooms connected by doors and '\n",
      "               'secret passages and guarded by monsters different from those '\n",
      "               'found on the Overworld. Link must successfully navigate each '\n",
      "               'Dungeon to obtain one of the eight pieces of the Triforce of '\n",
      "               'Wisdom. There is also the Overworld Exploration can I tell you '\n",
      "               'a bit about that?',\n",
      "          'a_meta': {'literal_obj': [{'endKey': '439cf729-7c83-493a-b5b2-8d2c1b90398b',\n",
      "                                      'startKey': 'fd1d944a-6f88-49ff-b747-e2de9cc517a4',\n",
      "                                      'text': 'Dungeon Exploration\\n'\n",
      "                                              \"Barring Link 's progress are \"\n",
      "                                              'Creatures he must battle to '\n",
      "                                              'locate the entrances to nine '\n",
      "                                              'underground Dungeons .'}],\n",
      "                     'pragmatic_obj': [{'endKey': '439cf729-7c83-493a-b5b2-8d2c1b90398b',\n",
      "                                        'startKey': '439cf729-7c83-493a-b5b2-8d2c1b90398b',\n",
      "                                        'text': 'Each Dungeon is a unique, '\n",
      "                                                'maze-like collection of rooms '\n",
      "                                                'connected by doors and secret '\n",
      "                                                'passages and guarded by '\n",
      "                                                'monsters different from those '\n",
      "                                                'found on the Overworld .'}]},\n",
      "          'human_eval': ['3', '3', '3', '2', '2'],\n",
      "          'q': 'What settings have appeared in this and other games in the '\n",
      "               'series?'},\n",
      "         {'a': 'The Overworld Exploration setting a non-linearity, the ability '\n",
      "               'to take different paths to complete the game, separated The '\n",
      "               'Legend of Zelda from its contemporaries.  Link can freely '\n",
      "               'wander the Overworld , finding and buying items at any point.  '\n",
      "               'This flexibility enables unusual ways of playing the game; for '\n",
      "               \"example, it's possible to reach the final Boss of The Legend \"\n",
      "               'of Zelda (but not defeat him) without taking a Sword.  There '\n",
      "               'is also the Second Quest can I tell you a bit about that?',\n",
      "          'a_meta': {'literal_obj': [{'endKey': 'a789f5e4-b003-4099-bda6-95bc8542c140',\n",
      "                                      'startKey': 'fc788506-672d-42ae-9928-53219af35db9',\n",
      "                                      'text': 'Overworld Exploration'},\n",
      "                                     {'endKey': '1bd27025-bdf6-4605-94b3-e4782cda703c',\n",
      "                                      'startKey': '1bd27025-bdf6-4605-94b3-e4782cda703c',\n",
      "                                      'text': 'Non-linearity, the ability to '\n",
      "                                              'take different paths to '\n",
      "                                              'complete the game, separated '\n",
      "                                              'The Legend of Zelda from its '\n",
      "                                              'contemporaries.'},\n",
      "                                     {'endKey': '1bd27025-bdf6-4605-94b3-e4782cda703c',\n",
      "                                      'startKey': '8258eb9f-5b5e-401a-96d5-74ad441f6bed',\n",
      "                                      'text': 'Link can freely wander the '\n",
      "                                              'Overworld , finding and buying '\n",
      "                                              'items at any point. '}],\n",
      "                     'pragmatic_obj': [{'endKey': '1bd27025-bdf6-4605-94b3-e4782cda703c',\n",
      "                                        'startKey': '1bd27025-bdf6-4605-94b3-e4782cda703c',\n",
      "                                        'text': 'This flexibility enables '\n",
      "                                                'unusual ways of playing the '\n",
      "                                                \"game; for example, it's \"\n",
      "                                                'possible to reach the final '\n",
      "                                                'Boss of The Legend of Zelda '\n",
      "                                                '(but not defeat him) without '\n",
      "                                                'taking a Sword .'}]},\n",
      "          'human_eval': ['4', '4', '3', '3', '3'],\n",
      "          'q': 'Yes I would like to learn more about the overworld.'},\n",
      "         {'a': 'The Second Quest...  after completing the game a player has '\n",
      "               'access to the Second Quest where Dungeons and the placement of '\n",
      "               'items are different with Enemies stronger. Although a more '\n",
      "               'difficult \"replay\" wasn\\'t unique to The Legend of Zelda, few '\n",
      "               'games offered a \"second quest\" with entirely different levels '\n",
      "               'to complete. Entering \"ZELDA\" as the player\\'s name starts the '\n",
      "               'Second Quest immediately. The Second Quest can be replayed '\n",
      "               \"each time it's completed. Would you like to know some Game \"\n",
      "               'Information?',\n",
      "          'a_meta': {'literal_obj': [{'endKey': '8779aa07-5c7c-43bc-a0b6-a3f9889d251d',\n",
      "                                      'startKey': '8779aa07-5c7c-43bc-a0b6-a3f9889d251d',\n",
      "                                      'text': 'Second Quest'},\n",
      "                                     {'endKey': '9f85a5ac-40eb-4f0f-af6a-4eb41380ac50',\n",
      "                                      'startKey': '9f85a5ac-40eb-4f0f-af6a-4eb41380ac50',\n",
      "                                      'text': 'After completing the game, the '\n",
      "                                              'player has access to a more '\n",
      "                                              'difficult quest, officially '\n",
      "                                              'referred to as the Second Quest '\n",
      "                                              ', where Dungeons and the '\n",
      "                                              'placement of items are '\n",
      "                                              'different, with Enemies '\n",
      "                                              'stronger. '},\n",
      "                                     {'endKey': '9f85a5ac-40eb-4f0f-af6a-4eb41380ac50',\n",
      "                                      'startKey': '9f85a5ac-40eb-4f0f-af6a-4eb41380ac50',\n",
      "                                      'text': ' Although a more difficult '\n",
      "                                              '\"replay\" wasn\\'t unique to The '\n",
      "                                              'Legend of Zelda , few games '\n",
      "                                              'offered a \"second quest\" with '\n",
      "                                              'entirely different levels to '\n",
      "                                              'complete.'}],\n",
      "                     'pragmatic_obj': [{'endKey': '9f85a5ac-40eb-4f0f-af6a-4eb41380ac50',\n",
      "                                        'startKey': '9f85a5ac-40eb-4f0f-af6a-4eb41380ac50',\n",
      "                                        'text': 'Entering \"ZELDA\" as the '\n",
      "                                                \"player's name starts the \"\n",
      "                                                'Second Quest immediately. The '\n",
      "                                                'Second Quest can be replayed '\n",
      "                                                \"each time it's completed.\"}]},\n",
      "          'human_eval': ['2', '2', '2', '2', '2'],\n",
      "          'q': 'Yes I would like to learn more about the second quest.'},\n",
      "         {'a': 'Game Information...Shortly before starting development for '\n",
      "               'Super Mario Bros. Shigeru Miyamoto began developing The Legend '\n",
      "               'of Zelda as a title for the Famicom Disk System. Miyamoto got '\n",
      "               'inspiration from his own explorations to the countryside and '\n",
      "               'hillsides around his home for an adventure game. Seeking to '\n",
      "               'create a fairytale setting co-developer Takashi Tezuka drew '\n",
      "               \"inspiration from J. R. R. Tolkien's Lord of the Rings novels \"\n",
      "               'when writing the story. Would you like more Game Information?',\n",
      "          'a_meta': {'literal_obj': [{'endKey': 'f72752bb-8b4e-4a04-9fc5-7a70e4afcc56',\n",
      "                                      'startKey': 'f72752bb-8b4e-4a04-9fc5-7a70e4afcc56',\n",
      "                                      'text': 'Game Information'},\n",
      "                                     {'endKey': '277c7940-6ca9-4e98-bc1a-ff19b25deaff',\n",
      "                                      'startKey': '277c7940-6ca9-4e98-bc1a-ff19b25deaff',\n",
      "                                      'text': 'Development'},\n",
      "                                     {'endKey': '1c4b9e48-a593-468c-a5ea-7e2849a3416a',\n",
      "                                      'startKey': '1c4b9e48-a593-468c-a5ea-7e2849a3416a',\n",
      "                                      'text': 'Shortly before starting '\n",
      "                                              'development for Super Mario '\n",
      "                                              'Bros. , Shigeru Miyamoto began '\n",
      "                                              'developing The Legend of Zelda '\n",
      "                                              'as a launch title for the '\n",
      "                                              'Famicom Disk System. '},\n",
      "                                     {'endKey': '1c4b9e48-a593-468c-a5ea-7e2849a3416a',\n",
      "                                      'startKey': '1c4b9e48-a593-468c-a5ea-7e2849a3416a',\n",
      "                                      'text': ' Miyamoto got inspiration from '\n",
      "                                              'his own explorations to the '\n",
      "                                              'countryside and hillsides '\n",
      "                                              'around his home for an '\n",
      "                                              'adventure game.'}],\n",
      "                     'pragmatic_obj': [{'endKey': '1c4b9e48-a593-468c-a5ea-7e2849a3416a',\n",
      "                                        'startKey': '1c4b9e48-a593-468c-a5ea-7e2849a3416a',\n",
      "                                        'text': 'Seeking to create a fairytale '\n",
      "                                                'setting, co-developer Takashi '\n",
      "                                                'Tezuka drew inspiration from '\n",
      "                                                \"J. R. R. Tolkien's Lord of \"\n",
      "                                                'the Rings novels when writing '\n",
      "                                                'the story. '}]},\n",
      "          'human_eval': ['3', '3', '2', '2', '2'],\n",
      "          'q': 'Yeah that sounds good. I would like to know who is credited '\n",
      "               'for creating the game. Is there a person who had the idea for '\n",
      "               'Zelda?'}],\n",
      " 'topic': 'The Legend of Zelda'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(pcqa_test[0])  # Print the first item in the test set to see its structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3878d204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: The Legend of Zelda\n",
      "Question: What year did the Legend of Zelda come out?\n",
      "Literal spans: ['FDS release February 21, 1986\\n', 'The Legend of Zelda is the first installment of the Zelda series. ', ' It centers its plot around a boy named Link , who becomes the central protagonist throughout the series. ']\n",
      "Pragmatic spans: ['It came out as early as 1986 for the Famicom in Japan, and was later released in the western world, including Europe and the US in 1987.']\n",
      "Expected Answer: The Legend of Zelda came out as early as 1986 for the Famicom in Japan, and was later released in the western world, including Europe and the US in 1987. Would you like to know about the story?\n"
     ]
    }
   ],
   "source": [
    "# Evaluate simple RAG on a specific topic: compare predicted answer to literal answer.\n",
    "s = pcqa_test[0]\n",
    "topic = s['topic']\n",
    "qa = s['qas'][0]\n",
    "question = qa['q']\n",
    "answer = qa['a']\n",
    "lit_spans = [l['text'] for l in qa['a_meta']['literal_obj']]\n",
    "lit_answer = ' '.join(lit_spans)\n",
    "prag_spans = [l['text'] for l in qa['a_meta']['pragmatic_obj']]\n",
    "prag_answer = ' '.join(prag_spans)\n",
    "\n",
    "print(f\"Topic: {topic}\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Literal spans: {lit_spans}\")\n",
    "print(f\"Pragmatic spans: {prag_spans}\")\n",
    "print(f\"Expected Answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "801f246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/22 16:12:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Both structured output format and JSON mode failed. Please choose a model that supports `response_format` argument. Original error: litellm.AuthenticationError: AuthenticationError: XaiException - {\"error\":{\"code\":401,\"message\":\"No or an invalid authentication header was provided on the request. Please make sure you pass your API key in the corresponding HTTP header.\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:171\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._make_common_sync_call\u001b[39m\u001b[34m(self, sync_httpx_client, provider_config, api_base, headers, data, timeout, litellm_params, logging_obj, stream, signed_json_body)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     response = \u001b[43msync_httpx_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[43msigned_json_body\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py:780\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    779\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mstatus_code\u001b[39m\u001b[33m\"\u001b[39m, e.response.status_code)\n\u001b[32m--> \u001b[39m\u001b[32m780\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py:762\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    761\u001b[39m response = \u001b[38;5;28mself\u001b[39m.client.send(req, stream=stream)\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '401 Unauthorized' for url 'https://api.x.ai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:1800\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   1794\u001b[39m         logging.post_call(\n\u001b[32m   1795\u001b[39m             \u001b[38;5;28minput\u001b[39m=messages,\n\u001b[32m   1796\u001b[39m             api_key=api_key,\n\u001b[32m   1797\u001b[39m             original_response=\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m   1798\u001b[39m             additional_args={\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: headers},\n\u001b[32m   1799\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1801\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mgroq\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:1774\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1774\u001b[39m     response = \u001b[43mbase_llm_http_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1775\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   1786\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1793\u001b[39m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:467\u001b[39m, in \u001b[36mBaseLLMHTTPHandler.completion\u001b[39m\u001b[34m(self, model, messages, api_base, custom_llm_provider, model_response, encoding, logging_obj, optional_params, timeout, litellm_params, acompletion, stream, fake_stream, api_key, headers, client, provider_config)\u001b[39m\n\u001b[32m    465\u001b[39m     sync_httpx_client = client\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_common_sync_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43msync_httpx_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43msync_httpx_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m provider_config.transform_response(\n\u001b[32m    479\u001b[39m     model=model,\n\u001b[32m    480\u001b[39m     raw_response=response,\n\u001b[32m   (...)\u001b[39m\u001b[32m    489\u001b[39m     json_mode=json_mode,\n\u001b[32m    490\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:196\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._make_common_sync_call\u001b[39m\u001b[34m(self, sync_httpx_client, provider_config, api_base, headers, data, timeout, litellm_params, logging_obj, stream, signed_json_body)\u001b[39m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:2405\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._handle_error\u001b[39m\u001b[34m(self, e, provider_config)\u001b[39m\n\u001b[32m   2399\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BaseLLMException(\n\u001b[32m   2400\u001b[39m         status_code=status_code,\n\u001b[32m   2401\u001b[39m         message=error_text,\n\u001b[32m   2402\u001b[39m         headers=error_headers,\n\u001b[32m   2403\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2405\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m provider_config.get_error_class(\n\u001b[32m   2406\u001b[39m     error_message=error_text,\n\u001b[32m   2407\u001b[39m     status_code=status_code,\n\u001b[32m   2408\u001b[39m     headers=error_headers,\n\u001b[32m   2409\u001b[39m )\n",
      "\u001b[31mOpenAIError\u001b[39m: {\"error\":{\"code\":401,\"message\":\"No or an invalid authentication header was provided on the request. Please make sure you pass your API key in the corresponding HTTP header.\"}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/utils.py:1184\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m end_time = datetime.datetime.now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:3430\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3428\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3429\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3430\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3433\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2301\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2300\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2302\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:456\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\n\u001b[32m    457\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAuthenticationError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    458\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    459\u001b[39m         model=model,\n\u001b[32m    460\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    461\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m    462\u001b[39m     )\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m original_exception.status_code == \u001b[32m404\u001b[39m:\n",
      "\u001b[31mAuthenticationError\u001b[39m: litellm.AuthenticationError: AuthenticationError: XaiException - {\"error\":{\"code\":401,\"message\":\"No or an invalid authentication header was provided on the request. Please make sure you pass your API key in the corresponding HTTP header.\"}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py:42\u001b[39m, in \u001b[36mChatAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# fallback to JSONAdapter\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/base.py:119\u001b[39m, in \u001b[36mAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m    117\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m.format(processed_signature, demos, inputs)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m outputs = \u001b[43mlm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_postprocess(signature, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/clients/base_lm.py:96\u001b[39m, in \u001b[36mBaseLM.__call__\u001b[39m\u001b[34m(self, prompt, messages, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt=\u001b[38;5;28;01mNone\u001b[39;00m, messages=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m._process_lm_response(response, prompt, messages, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/clients/lm.py:127\u001b[39m, in \u001b[36mLM.forward\u001b[39m\u001b[34m(self, prompt, messages, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m completion, litellm_cache_args = \u001b[38;5;28mself\u001b[39m._get_cached_completion_fn(completion, cache, enable_memory_cache)\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m results = \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_cache_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(c.finish_reason == \u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m results[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/clients/cache.py:232\u001b[39m, in \u001b[36mrequest_cache.<locals>.decorator.<locals>.sync_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# Otherwise, compute and store the result\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# `enable_memory_cache` can be provided at call time to avoid indefinite growth.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/clients/lm.py:304\u001b[39m, in \u001b[36mlitellm_completion\u001b[39m\u001b[34m(request, num_retries, cache)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream_completion \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexponential_backoff_retry\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream_completion()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/utils.py:1289\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1288\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_retries\u001b[39m\u001b[33m\"\u001b[39m] = num_retries\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1290\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(e, litellm.exceptions.ContextWindowExceededError)\n\u001b[32m   1292\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m context_window_fallback_dict\n\u001b[32m   1293\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m context_window_fallback_dict\n\u001b[32m   1294\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_litellm_router_call\n\u001b[32m   1295\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:3468\u001b[39m, in \u001b[36mcompletion_with_retries\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3465\u001b[39m     retryer = tenacity.Retrying(\n\u001b[32m   3466\u001b[39m         stop=tenacity.stop_after_attempt(num_retries), reraise=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3467\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m3468\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretryer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.10-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.10-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/utils.py:1309\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1306\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1307\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1308\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1309\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/utils.py:1184\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m end_time = datetime.datetime.now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:3430\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3428\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3429\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3430\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3433\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2301\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2300\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2302\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:456\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\n\u001b[32m    457\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAuthenticationError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    458\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    459\u001b[39m         model=model,\n\u001b[32m    460\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    461\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m    462\u001b[39m     )\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m original_exception.status_code == \u001b[32m404\u001b[39m:\n",
      "\u001b[31mAuthenticationError\u001b[39m: litellm.AuthenticationError: AuthenticationError: XaiException - {\"error\":{\"code\":401,\"message\":\"No or an invalid authentication header was provided on the request. Please make sure you pass your API key in the corresponding HTTP header.\"}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py:62\u001b[39m, in \u001b[36mJSONAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     structured_output_model = \u001b[43m_get_structured_outputs_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     lm_kwargs[\u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m] = structured_output_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py:220\u001b[39m, in \u001b[36m_get_structured_outputs_response_format\u001b[39m\u001b[34m(signature)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# Build the model with extra fields forbidden.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m pydantic_model = \u001b[43mpydantic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDSPyProgramOutputs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m__config__\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mConfig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mextra\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforbid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# Generate the initial schema.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/pydantic/main.py:1763\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(model_name, __config__, __doc__, __base__, __module__, __validators__, __cls_kwargs__, **field_definitions)\u001b[39m\n\u001b[32m   1761\u001b[39m namespace.update(ns)\n\u001b[32m-> \u001b[39m\u001b[32m1763\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1764\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1765\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresolved_bases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1767\u001b[39m \u001b[43m    \u001b[49m\u001b[43m__pydantic_reset_parent_namespace__\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1768\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_create_model_module\u001b[49m\u001b[43m=\u001b[49m\u001b[34;43m__module__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1769\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1770\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:110\u001b[39m, in \u001b[36mModelMetaclass.__new__\u001b[39m\u001b[34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m base_field_names, class_vars, base_private_attributes = mcs._collect_bases_data(bases)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m config_wrapper = \u001b[43mConfigWrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfor_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m namespace[\u001b[33m'\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m'\u001b[39m] = config_wrapper.config_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:138\u001b[39m, in \u001b[36mConfigWrapper.for_model\u001b[39m\u001b[34m(cls, bases, namespace, kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m config_from_namespace = config_dict_from_namespace \u001b[38;5;129;01mor\u001b[39;00m prepare_config(config_class_from_namespace)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[43mconfig_new\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_from_namespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(kwargs.keys()):\n",
      "\u001b[31mTypeError\u001b[39m: 'type' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:171\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._make_common_sync_call\u001b[39m\u001b[34m(self, sync_httpx_client, provider_config, api_base, headers, data, timeout, litellm_params, logging_obj, stream, signed_json_body)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     response = \u001b[43msync_httpx_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[43msigned_json_body\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py:780\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    779\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mstatus_code\u001b[39m\u001b[33m\"\u001b[39m, e.response.status_code)\n\u001b[32m--> \u001b[39m\u001b[32m780\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py:762\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    761\u001b[39m response = \u001b[38;5;28mself\u001b[39m.client.send(req, stream=stream)\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '401 Unauthorized' for url 'https://api.x.ai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:1800\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   1794\u001b[39m         logging.post_call(\n\u001b[32m   1795\u001b[39m             \u001b[38;5;28minput\u001b[39m=messages,\n\u001b[32m   1796\u001b[39m             api_key=api_key,\n\u001b[32m   1797\u001b[39m             original_response=\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m   1798\u001b[39m             additional_args={\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: headers},\n\u001b[32m   1799\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1801\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mgroq\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:1774\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1774\u001b[39m     response = \u001b[43mbase_llm_http_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1775\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   1786\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1793\u001b[39m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:467\u001b[39m, in \u001b[36mBaseLLMHTTPHandler.completion\u001b[39m\u001b[34m(self, model, messages, api_base, custom_llm_provider, model_response, encoding, logging_obj, optional_params, timeout, litellm_params, acompletion, stream, fake_stream, api_key, headers, client, provider_config)\u001b[39m\n\u001b[32m    465\u001b[39m     sync_httpx_client = client\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_common_sync_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43msync_httpx_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43msync_httpx_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m provider_config.transform_response(\n\u001b[32m    479\u001b[39m     model=model,\n\u001b[32m    480\u001b[39m     raw_response=response,\n\u001b[32m   (...)\u001b[39m\u001b[32m    489\u001b[39m     json_mode=json_mode,\n\u001b[32m    490\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:196\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._make_common_sync_call\u001b[39m\u001b[34m(self, sync_httpx_client, provider_config, api_base, headers, data, timeout, litellm_params, logging_obj, stream, signed_json_body)\u001b[39m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:2405\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._handle_error\u001b[39m\u001b[34m(self, e, provider_config)\u001b[39m\n\u001b[32m   2399\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BaseLLMException(\n\u001b[32m   2400\u001b[39m         status_code=status_code,\n\u001b[32m   2401\u001b[39m         message=error_text,\n\u001b[32m   2402\u001b[39m         headers=error_headers,\n\u001b[32m   2403\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2405\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m provider_config.get_error_class(\n\u001b[32m   2406\u001b[39m     error_message=error_text,\n\u001b[32m   2407\u001b[39m     status_code=status_code,\n\u001b[32m   2408\u001b[39m     headers=error_headers,\n\u001b[32m   2409\u001b[39m )\n",
      "\u001b[31mOpenAIError\u001b[39m: {\"error\":{\"code\":401,\"message\":\"No or an invalid authentication header was provided on the request. Please make sure you pass your API key in the corresponding HTTP header.\"}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/utils.py:1184\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m end_time = datetime.datetime.now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:3430\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3428\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3429\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3430\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3433\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2301\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2300\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2302\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:456\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\n\u001b[32m    457\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAuthenticationError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    458\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    459\u001b[39m         model=model,\n\u001b[32m    460\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    461\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m    462\u001b[39m     )\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m original_exception.status_code == \u001b[32m404\u001b[39m:\n",
      "\u001b[31mAuthenticationError\u001b[39m: litellm.AuthenticationError: AuthenticationError: XaiException - {\"error\":{\"code\":401,\"message\":\"No or an invalid authentication header was provided on the request. Please make sure you pass your API key in the corresponding HTTP header.\"}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py:69\u001b[39m, in \u001b[36mJSONAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     68\u001b[39m     lm_kwargs[\u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mjson_object\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AdapterParseError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# On AdapterParseError, we raise the original error.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py:50\u001b[39m, in \u001b[36mChatAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ContextWindowExceededError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, JSONAdapter):\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# On context window exceeded error or already using JSONAdapter, we don't want to retry with a different\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# adapter.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py:42\u001b[39m, in \u001b[36mChatAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# fallback to JSONAdapter\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/base.py:119\u001b[39m, in \u001b[36mAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m    117\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m.format(processed_signature, demos, inputs)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m outputs = \u001b[43mlm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_postprocess(signature, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/clients/base_lm.py:96\u001b[39m, in \u001b[36mBaseLM.__call__\u001b[39m\u001b[34m(self, prompt, messages, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt=\u001b[38;5;28;01mNone\u001b[39;00m, messages=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m._process_lm_response(response, prompt, messages, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/clients/lm.py:127\u001b[39m, in \u001b[36mLM.forward\u001b[39m\u001b[34m(self, prompt, messages, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m completion, litellm_cache_args = \u001b[38;5;28mself\u001b[39m._get_cached_completion_fn(completion, cache, enable_memory_cache)\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m results = \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_cache_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(c.finish_reason == \u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m results[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/clients/cache.py:232\u001b[39m, in \u001b[36mrequest_cache.<locals>.decorator.<locals>.sync_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# Otherwise, compute and store the result\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# `enable_memory_cache` can be provided at call time to avoid indefinite growth.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/clients/lm.py:304\u001b[39m, in \u001b[36mlitellm_completion\u001b[39m\u001b[34m(request, num_retries, cache)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream_completion \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexponential_backoff_retry\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream_completion()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/utils.py:1289\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1288\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_retries\u001b[39m\u001b[33m\"\u001b[39m] = num_retries\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1290\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(e, litellm.exceptions.ContextWindowExceededError)\n\u001b[32m   1292\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m context_window_fallback_dict\n\u001b[32m   1293\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m context_window_fallback_dict\n\u001b[32m   1294\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_litellm_router_call\n\u001b[32m   1295\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:3468\u001b[39m, in \u001b[36mcompletion_with_retries\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3465\u001b[39m     retryer = tenacity.Retrying(\n\u001b[32m   3466\u001b[39m         stop=tenacity.stop_after_attempt(num_retries), reraise=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3467\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m3468\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretryer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.10-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.10-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/utils.py:1309\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1306\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1307\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1308\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1309\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/utils.py:1184\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m end_time = datetime.datetime.now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/main.py:3430\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3428\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3429\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3430\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3433\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2301\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2300\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2302\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:456\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\n\u001b[32m    457\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAuthenticationError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    458\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    459\u001b[39m         model=model,\n\u001b[32m    460\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    461\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m    462\u001b[39m     )\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m original_exception.status_code == \u001b[32m404\u001b[39m:\n",
      "\u001b[31mAuthenticationError\u001b[39m: litellm.AuthenticationError: AuthenticationError: XaiException - {\"error\":{\"code\":401,\"message\":\"No or an invalid authentication header was provided on the request. Please make sure you pass your API key in the corresponding HTTP header.\"}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m search = make_search(topic)\n\u001b[32m      2\u001b[39m rag = RAG(search)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m pred_answer = \u001b[43mrag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m.response\n\u001b[32m      4\u001b[39m context = rag.search(question).passages\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredicted Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_answer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/primitives/program.py:60\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m     output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mRAG.forward\u001b[39m\u001b[34m(self, question)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, question):\n\u001b[32m     35\u001b[39m     context = \u001b[38;5;28mself\u001b[39m.search(question).passages\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrespond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/primitives/program.py:60\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m     output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/predict/chain_of_thought.py:38\u001b[39m, in \u001b[36mChainOfThought.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/predict/predict.py:85\u001b[39m, in \u001b[36mPredict.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m._get_positional_args_error_message())\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/primitives/program.py:60\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m     output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/predict/predict.py:157\u001b[39m, in \u001b[36mPredict.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m settings.context(send_stream=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         completions = \u001b[43madapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_postprocess(completions, signature, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py:51\u001b[39m, in \u001b[36mChatAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ContextWindowExceededError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, JSONAdapter):\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# On context window exceeded error or already using JSONAdapter, we don't want to retry with a different\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# adapter.\u001b[39;00m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mJSONAdapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM's HW/hw3/nlp-with-llms-2025-hw3/.venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py:75\u001b[39m, in \u001b[36mJSONAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# On any other error, we raise a RuntimeError with the original error message.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     76\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBoth structured output format and JSON mode failed. Please choose a model that supports \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`response_format` argument. Original error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Both structured output format and JSON mode failed. Please choose a model that supports `response_format` argument. Original error: litellm.AuthenticationError: AuthenticationError: XaiException - {\"error\":{\"code\":401,\"message\":\"No or an invalid authentication header was provided on the request. Please make sure you pass your API key in the corresponding HTTP header.\"}}"
     ]
    }
   ],
   "source": [
    "search = make_search(topic)\n",
    "rag = RAG(search)\n",
    "pred_answer = rag(question).response\n",
    "context = rag.search(question).passages\n",
    "print(f\"Predicted Answer: {pred_answer}\")\n",
    "print(f\"Context: {context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc08497",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m metric = SemanticF1(decompositional=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Produce a prediction from the RAG module.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m example = dspy.Example(question=question, response=answer, inputs={\u001b[33m'\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mcontext\u001b[49m})\n\u001b[32m      8\u001b[39m pred = rag(example.question)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Compute the metric score for the prediction.\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'context' is not defined"
     ]
    }
   ],
   "source": [
    "from dspy.evaluate import SemanticF1\n",
    "\n",
    "# Instantiate the metric.\n",
    "metric = SemanticF1(decompositional=True)\n",
    "\n",
    "# Produce a prediction from the RAG module.\n",
    "example = dspy.Example(question=question, response=answer, inputs={'context': context})\n",
    "pred = rag(example.question)\n",
    "\n",
    "# Compute the metric score for the prediction.\n",
    "score = metric(example, pred)\n",
    "\n",
    "print(f\"Question: \\t {example.question}\\n\")\n",
    "print(f\"Gold Response: \\t {example.response}\\n\")\n",
    "print(f\"Predicted Response: \\t {pred.response}\\n\")\n",
    "print(f\"Semantic F1 Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a9ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Literal Answer: FDS release February 21, 1986\n",
      " The Legend of Zelda is the first installment of the Zelda series.   It centers its plot around a boy named Link , who becomes the central protagonist throughout the series. \n",
      "Score for Literal Answer: 0.33\n",
      "Pragmatic Answer: It came out as early as 1986 for the Famicom in Japan, and was later released in the western world, including Europe and the US in 1987.\n",
      "Score for Pragmatic Answer: 0.80\n"
     ]
    }
   ],
   "source": [
    "print(f\"Literal Answer: {lit_answer}\")\n",
    "print(f\"Score for Literal Answer: {metric(example, dspy.Example(question=question, response=lit_answer, inputs={'context': context})):.2f}\")\n",
    "\n",
    "print(f\"Pragmatic Answer: {prag_answer}\")\n",
    "print(f\"Score for Pragmatic Answer: {metric(example, dspy.Example(question=question, response=prag_answer, inputs={'context': context})):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6d634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cost: 0.00 usd\n"
     ]
    }
   ],
   "source": [
    "cost = sum([x['cost'] for x in lm.history if x['cost'] is not None])\n",
    "print(f\"Total Cost: {cost:.2f} usd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
